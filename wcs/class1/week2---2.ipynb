{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Neural Network mindset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just a feeling test on deeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy \n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from lr_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set_x_orig,train_set_y,test_set_x_orig,test_set_y,classes=load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y =  [1] , it's a ' cat ' picture.\n"
     ]
    }
   ],
   "source": [
    "index=25\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" , str(train_set_y[:, index]) , \", it's a '\" ,classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") ,  \"' picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the information of trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples: m_train=  209\n",
      "number of test examples: m_test=  50\n",
      "height/width of each image: num_px=  64\n",
      "sss 64\n"
     ]
    }
   ],
   "source": [
    "m_train=train_set_x_orig.shape[0]\n",
    "m_test=test_set_x_orig.shape[0]\n",
    "num_px=train_set_x_orig.shape[1]\n",
    "num_px2=train_set_x_orig.shape[2]\n",
    "print(\"number of training examples: m_train= \",m_train)\n",
    "print(\"number of test examples: m_test= \",m_test)\n",
    "print(\"height/width of each image: num_px= \",num_px)\n",
    "print(\"sss\",num_px2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flattern shape:  (12288, 209)\n",
      "test_set_x_flattern shape:  (12288, 50)\n",
      "sanity check after reshape:  [ 17 196  82   1   9  84  56  19  63  23]\n"
     ]
    }
   ],
   "source": [
    "# reshape them  np.array(train_set_x_orig)\n",
    "#the first level stay stable, others flatern.\n",
    "train_set_x_flatten=train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T\n",
    "test_set_x_flatten=test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T\n",
    "print(\"train_set_x_flattern shape: \",train_set_x_flatten.shape)\n",
    "print(\"test_set_x_flattern shape: \",test_set_x_flattern.shape)\n",
    "print(\"sanity check after reshape: \",train_set_x_flatten[0,0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#standard the data\n",
    "train_set_x=train_set_x_flatten/255.\n",
    "test_set_x=test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the parts of our algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. define the model structure\n",
    "2. initialize model's parameters\n",
    "3. Loop:\n",
    "   calculate current loss(forward propagation)\n",
    "   calculate current gradient(backward propagation)\n",
    "   update parameters (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from basic_me import np_sigmoid\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    compute the sigmoid of z\n",
    "    Arguments:\n",
    "     z-- a scalar or numpy array of any size\n",
    "     return :\n",
    "     s--- sigmoid(z)\n",
    "    \"\"\"\n",
    "    s=np_sigmoid(z)\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 2]) = [ 0.5         0.88079708]\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 initialzing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    w --0 vector and b--0\n",
    "    Augument:\n",
    "    dim -- size of w vector \n",
    "    \n",
    "    returns :\n",
    "    w -- vector \n",
    "    b -- scalar\n",
    "    \"\"\"\n",
    "    #!!!attention ,can not use np.zeros(dim)\n",
    "    w=np.zeros((dim,1))\n",
    "    b=0\n",
    "    assert(w.shape==(dim,1))\n",
    "    assert(isinstance(b,float)or isinstance(b,int))\n",
    "    return w,b\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "w=  [[ 0.]\n",
      " [ 0.]]\n",
      "b=  0\n"
     ]
    }
   ],
   "source": [
    "dim =2\n",
    "w,b=initialize_with_zeros(dim)\n",
    "ww=w.shape[0]\n",
    "print(ww)\n",
    "print(\"w= \",w)\n",
    "print(\"b= \",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3  forward and backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this roi is weak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  5  6]\n",
      " [ 8 10 12]\n",
      " [12 15 18]]\n",
      "[[ 4  5  6]\n",
      " [ 8 10 12]\n",
      " [12 15 18]]\n",
      "[[ 0.          0.69314718  1.09861229]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "xxx=np.array([[1,2,3]])\n",
    "zzz=np.array([[4,5,6]])\n",
    "print(xxx.T*zzz)\n",
    "print(np.dot(xxx.T,zzz))\n",
    "yyy=np.log(xxx)\n",
    "1-xxx\n",
    "print(np.log(xxx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from basic_me import np_sigmoid\n",
    "def propagate(w,b,X,Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    w --- weights , a numpy array of size (num_px*num_px*3,1),wihch is equal to image pixels number\n",
    "    b --- bias , a scalar\n",
    "    X --- data of size (num_px*num_px*3, number of examples)\n",
    "    Y --- true label of size( 1, number of examples )\n",
    "    \"\"\"\n",
    "    #m --- number of examples\n",
    "    m=X.shape[1]\n",
    "    \n",
    "    #A=w.T*X+b    my wrong and view the solution.....\n",
    "    A=np_sigmoid(np.dot(w.T,X)+b)\n",
    "    #Y*np.log(A)+(1-Y)np.log(1-A)  #mine is right , but i did not go on .......\n",
    "    cost=-1/m*np.sum(Y*np.log(A)+(1-Y)*np.log(1-A))\n",
    "    #be attention to use np.dot() but not A.T....\n",
    "    #dw=1/m*X(A-Y).T\n",
    "    dw=1/m*np.dot(X,(A-Y).T)\n",
    "    db=1/m*np.sum(A-Y)\n",
    "    \n",
    "    assert(dw.shape==w.shape)\n",
    "    assert(db.dtype==float)\n",
    "    cost=np.squeeze(cost)\n",
    "    assert(cost.shape==())\n",
    "    grads={\"dw\":dw,\n",
    "          \"db\":db}\n",
    "    return grads,cost\n",
    "    \n",
    "                     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw =  [[ 0.99993216]\n",
      " [ 1.99980262]]\n",
      "db =  0.499935230625\n",
      "cost =  6.00006477319\n"
     ]
    }
   ],
   "source": [
    "w, b, X, Y = np.array([[1],[2]]), 2, np.array([[1,2],[3,4]]), np.array([[1,0]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" ,grads[\"dw\"])\n",
    "print (\"db = \" , grads[\"db\"])\n",
    "print (\"cost = \" , cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "temp1=np.array([[1,2,3],\n",
    "               [3,4,5]])\n",
    "temp2=np.array([3,4,5])\n",
    "temp3=np.sum(temp1)\n",
    "print(temp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the update rule is $ \\theta = \\theta - \\alpha \\text{ }d\\theta $  \n",
    "and $ \\alpha $ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(w,b,X,Y,num_iterations,learning_rate,print_cost=False):\n",
    "    \"\"\"\n",
    "    this function optimizes w and b by runting a gradient descent.\n",
    "    Arguments: \n",
    "    w---weights, a numpy of size(num_px*num_px*3,1)\n",
    "    b---bias, a scalar\n",
    "    X--- data of shape(num_px*num_px*3,number of examples)\n",
    "    Y--- true \"label\" vector of shape(1, number of examples)\n",
    "    num_iterations --- number of iterations of the optimization loop \n",
    "    learning_rate --- learning rate of the gradient descent update rule \n",
    "    print_cost --- true to print the loss every 100 steps\n",
    "    \n",
    "    returns :\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve .\n",
    "    \"\"\"\n",
    "    costs=[]\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
